# Trabajo Pr√°ctico Final Foundations
### ITBA - Cloud Data Engineering

Bienvenido al TP Final de la secci√≥n Foundations del M√≥dulo 1 de la Diplomatura en Cloud Data Engineering del ITBA.

En este trabajo pr√°ctico vas a poner en pr√°ctica los conocimientos adquiridos en: 

1. Bases de Datos Relacionales (PostgreSQL espec√≠ficamente).
2. BASH y Linux Commandline.
3. Python 3.7+.
4. Docker.

Para realizar este TP vamos a utlizar la plataforma Github Classrooms donde cada alumno tendr√° acceso a un repositorio de Git privado hosteado en la plataforma Github.

En cada repositorio, en la secci√≥n de [Issues](https://guides.github.com/features/issues/) (tab a la derecha de Code en las tabs de navegaci√≥n en la parte superior de la pantalla) podr√°s ver que hay creado un issue por cada ejercicio. 
El objetivo es resolver ejercicio/issue creando un branch y un pull request asociado. 

Debido a que cada ejercico utiliza el avance realizado en el issue anterior, cada nuevo branch debe partir del branch del ejercicio anterior.

Para poder realizar llevar a cabo esto puede realizarlo desde la web de Github pero recomendamos hacerlo con la aplicaci√≥n de l√≠nea de comando de git o con la aplicaci√≥n de [Github Desktop](https://desktop.github.com/) (interfaz visual) o [Github CLI](https://cli.github.com/) (interfaz de l√≠nea de comando).

La idea de utilizar Github es replicar el ambiente de un proyecto real donde las tareas se deber√≠an definir como issues y cada nuevo feature se deber√≠a crear con un Pull Request correspondiente que lo resuelve. 
https://guides.github.com/introduction/flow/
https://docs.github.com/en/github/getting-started-with-github/quickstart/github-flow

**MUY IMPORTANTE: parte importante del Trabajo Pr√°ctico es aprender a buscar en Google para poder resolver de manera exitosa el trabajo pr√°ctico**

## Ejercicios

### Ejercicio 1: Elecci√≥n de dataset y preguntas

Elegir un dataset de la [wiki de PostgreSQL ](https://wiki.postgresql.org/wiki/Sample_Databases) u otra fuente que sea de inter√©s para el alumno.

Crear un Pull Request con un archivo en [formato markdown](https://guides.github.com/features/mastering-markdown/) expliando el dataset elegido y  una breve descripci√≥n de al menos 4 preguntas de negocio que se podr√≠an responder teniendo esos datos en una base de datos relacional de manera que sean consultables con lenguaje SQL.


Otras fuentes de datos abiertos sugeridas:
https://catalog.data.gov/dataset
https://datasetsearch.research.google.com/
https://www.kaggle.com/datasets

## Ejercicio 2: Crear container de la DB

Crear un archivo de [docker-compose](https://docs.docker.com/compose/gettingstarted/) que cree un container de [Docker](https://docs.docker.com/get-started/) con una base de datos PostgreSQL con la versi√≥n 12.7.
Recomendamos usar la [imagen oficial de PostgreSQL](https://hub.docker.com/_/postgres) disponible en Docker Hub.
 
Se debe exponer el puerto est√°ndar de esa base de datos para que pueda recibir conexiones desde la m√°quina donde se levante el container.


## Ejercicio 3: Script para creaci√≥n de tablas

Crear un script de bash que ejecute uno o varios scripts SQL que creen las tablas de la base de datos en la base PostgreSQL creada en el container del ejercicio anterior.

Se deben solamente crear las tablas, primary keys, foreign keys y otras operaciones de [DDL](https://en.wikipedia.org/wiki/Data_definition_language) sin crear o insertar los datos. 

## Ejercicio 4: Popular la base de datos

Crear un script de Python que una vez que el container se encuentre funcionando y se hayan ejecutado todas las operaciones de DDL necesarias, popule la base de datos con el dataset elegido.

La base de datos debe quedar lista para recibir consultas. Durante la carga de informaci√≥n puede momentareamente remover cualquier constraint que no le permita insertar la informaci√≥n pero luego debe volverla a crear.

Este script debe ejecutarse dentro de un nuevo container de Docker mediante el comando `docker run`.

El container de Docker generado para no debe contener los datos crudos que se utilizar√≠an para cargar la base.
Para pasar los archivos con los datos, se puede montar un volumen (argumento `-v` de `docker run`) o bien bajarlos directamente desde Internet usando alguna librer√≠a de Python (como `requests`).


## Ejercicio 5: Consultas a la base de datos

Escribir un script de Python que realice al menos 5 consultas SQL que puedan agregar valor al negocio y muestre por pantalla un reporte con los resultados.

Este script de reporting debe correrse mediante una imagen de Docker con `docker run` del mismo modo que el script del ejercicio 4.

## Ejercicio 6: Documentaci√≥n y ejecuci√≥n end2end

Agregue una secci√≥n al README.md comentando como resolvi√≥ los ejercicios, linkeando al archivo con la descripci√≥n del dataset y explicando como ejecutar un script de BASH para ejecutar todo el proceso end2end desde la creaci√≥n del container, operaciones de DDL, carga de datos y consultas. Para esto crear el archivo de BASH correspondiente. 

## Resoluci√≥n de ejercicios

### Elecci√≥n del dataset y preguntas
En el siguiente [link](https://github.com/flanfranco/tpf-foundations-flanfranco/blob/main/documentation/dataset_info.md) se detalla el dataset seleccionado, junto con su modelo de datos y las preguntas de an√°lisis a responder.

### Acerca de la soluci√≥n

Las tecnolog√≠as utilizadas para resolver los distintos apartados fueron:

1. Sistema operativo Linux Ubuntu 20.04
2. Docker y Docker-Compose 
3. DBeaver
4. Github

**¬øPor qu√© Docker-Compose?**

Se opt√≥ por Docker-Compose como orquestador sobre scripts de Bash principalmente porque ofrece un importante dinamismo a la hora de desplegar r√°pidamente una soluci√≥n productiva. A su vez Docker-Compose mantiene el tracking de manera nativa de todo lo que ocurre con los containers ejecutados, y como caracter√≠sticas fundamentales ofrece estandarizaci√≥n, legilibilidad, y portabilidad a la hora de definir la orquestaci√≥n, facilitando el mantenimiento de la misma. 

Es importante remarcar que la resoluci√≥n de los ejercicios podr√≠a llevarse a cabo completamente con scripts de Bash logrando los mismos resultados, utilizando piping (por ejemplo: `echo "SQL Query;" | docker exec -i  docker_postgres_db_1 psql -U username database`), variables (ejemplo: `docker run -v $(pwd)/csv_volume:/csv_volume my-app-image`) y estructuras l√≥gicas de comparaci√≥n e iteraci√≥n para gestionar la ejecuci√≥n de toda la orquestaci√≥n. Es en base a este √∫ltimo punto donde se opt√≥ por una soluci√≥n mas robusta como Docker-Compose para poder orquestar toda la ejecuci√≥n, y a su vez que esta soluci√≥n pueda servir como base para futuros trabajos pr√°cticos correspondientes a los pr√≥ximos m√≥dulos.


### Gu√≠a de ejecuci√≥n

Para poder ejecutar la soluci√≥n es requisito tener instalado Docker y Docker-Compose en el sistema operativo.

A continuaci√≥n se listan los pasos para desplegar la soluci√≥n:
1. Descargar el contenido del [repositorio](https://github.com/flanfranco/tpf-foundations-flanfranco.git)
2. Posicionados sobre la carpeta donde descargamos el contenido del repositorio ("tpf-foundations-flanfranco") se deber√≠a encontrar el archivo `docker-compose.yml` que contiene todas las especificaciones correspondientes al proceso de orquestaci√≥n.  All√≠ ejecutamos: `docker-compose up` para que se empiece a desplegar la soluci√≥n.
3. Una vez que la soluci√≥n termin√≥ de desplegarse deber√≠amos ver algo similar a la siguiente captura:
![Image of the Deployment](https://github.com/flanfranco/tpf-foundations-flanfranco/blob/main/documentation/resources/images/01_deploy_example.png)
4. Ya teniendo desplegada la soluci√≥n, para poder acceder a la Jupyter Notebook (que contiene el an√°lisis) solo har√≠a falta ingresar al siguiente [link](http://127.0.0.1:8888/?token=itba_jupyter_notebook_token): `http://127.0.0.1:8888/?token=itba_jupyter_notebook_token`
5. Una vez en el repositorio de Jupyter, deber√≠amos seleccionar la siguiente notebook `ITBA CDE TP Foundations Flavio Lanfranco.ipynb` como se muestra en la captura a continuaci√≥n:
![Image of the Deployment](https://github.com/flanfranco/tpf-foundations-flanfranco/blob/main/documentation/resources/images/03_jupyter_notebook_file.png) 
Logrando acceder, finalmente, a la notebook que contiene todo el an√°lisis interactivo para responder los [requerimientos planteados](https://github.com/flanfranco/tpf-foundations-flanfranco/blob/main/documentation/dataset_info.md).
![Image of the Deployment](https://github.com/flanfranco/tpf-foundations-flanfranco/blob/main/documentation/resources/images/04_jupyter_notebook_snapshot.png) 

### Comentarios acerca del desarrollo
En los siguientes apartados se comenta en detalle las principales consideraciones tenidas en cuenta en el desarrollo de la soluci√≥n:

1. En la siguiente captura se muestra y comenta el contenido del `docker-compose.yml` detallando las caracter√≠sticas principales definidas para la orquestaci√≥n:

![Image of the Deployment](https://github.com/flanfranco/tpf-foundations-flanfranco/blob/main/documentation/resources/images/05_docker_compose_yml.png) 

2. Con respecto a la creaci√≥n del container de la DB requerida en el Ejercicio 2, se comparte una captura del dockerfile donde adem√°s se muestra como se ejecuta la creaci√≥n del schema y tablas necesarias para el Ejercicio 3:

![Image of the Deployment](https://github.com/flanfranco/tpf-foundations-flanfranco/blob/main/documentation/resources/images/06_dockerfile_db.png)

3. En las siguientes capturas se muestra c√≥mo se llev√≥ adelante la resoluci√≥n del Ejercicio 4 definiendo el siguiente dockerfile y script de python:

![Image of the Deployment](https://github.com/flanfranco/tpf-foundations-flanfranco/blob/main/documentation/resources/images/07_dockerfile_app_load_db.png)

![Image of the Deployment](https://github.com/flanfranco/tpf-foundations-flanfranco/blob/main/documentation/resources/images/08_python_script_load_db.png)

5. Finalmente se comparte captura del dockerfile utilizado para resolver el Ejercicio 5:

![Image of the Deployment](https://github.com/flanfranco/tpf-foundations-flanfranco/blob/main/documentation/resources/images/09_dockerfile_jupyter.png)

### Notas finales
Es importante remarcar que se podr√≠a mejorar mucho mas la soluci√≥n presentada, por ejemplo, en lo referido al script de python para que considere control de excepciones, reintentos, logueo, etc... Todo esto podr√≠a desarrollarse como un framework para luego reutilizarse en otros proyectos. 
Tambi√©n, respecto a la parametrizaci√≥n de la soluci√≥n, los schemas, nombres de tablas/csv, y credenciales podr√≠an haberse definido en un archivo externo (json) evitando el harcodeo en el desarrollo y mejorando aspectos referidos a la seguridad.
A su vez se podr√≠an haber utilizado im√°genes de docker mucho mas peque√±as y b√°sicas que las presentadas, reduciendo considerablemente el espacio de almacenamiento necesario para desplegar la soluci√≥n.

La idea es que esta soluci√≥n sea el punto de partida (y de mejoras) para la realizaci√≥n de los futuros trabajos pr√°cticos correspondientes a los pr√≥ximos m√≥dulos de la diplomatura.

Gracias por el tiempo brindado!!!

üë®üèΩ‚Äçüíª Flavio Lanfranco
